"use strict";(self.webpackChunk_react_native_video_docs=self.webpackChunk_react_native_video_docs||[]).push([["7071"],{9112:function(e,r,n){n.r(r),n.d(r,{frontMatter:()=>o,toc:()=>d,default:()=>p,metadata:()=>s,assets:()=>l,contentTitle:()=>c});var s=JSON.parse('{"id":"frame-processor","title":"Frame Processor","description":"Real-time video frame processing for React Native Video","source":"@site/docs/frame-processor.mdx","sourceDirName":".","slug":"/frame-processor","permalink":"/react-native-video/docs/v7/frame-processor","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"planned","permalink":"/react-native-video/docs/v7/tags/planned"}],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"title":"Frame Processor","description":"Real-time video frame processing for React Native Video","tags":["planned"]},"sidebar":"docsSidebar","previous":{"title":"Google DAI \u{1F9E9}","permalink":"/react-native-video/docs/v7/ads/google-dai"},"next":{"title":"Basic Controls","permalink":"/react-native-video/docs/v7/custom-ui/basic-controls"}}'),t=n(4848),i=n(6151),a=n(4713);let o={sidebar_position:8,title:"Frame Processor",description:"Real-time video frame processing for React Native Video",tags:["planned"]},c="Frame Processor",l={},d=[{value:"Use Cases",id:"use-cases",level:2},{value:"Features",id:"features",level:2},{value:"Basic Usage",id:"basic-usage",level:2},{value:"Applying Filters",id:"applying-filters",level:2},{value:"Object Detection",id:"object-detection",level:2},{value:"Face Detection",id:"face-detection",level:2},{value:"Watermarking",id:"watermarking",level:2},{value:"Performance Tips",id:"performance-tips",level:2},{value:"Get Started",id:"get-started",level:2}];function m(e){let r={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.header,{children:(0,t.jsx)(r.h1,{id:"frame-processor",children:"Frame Processor"})}),"\n",(0,t.jsx)(a.A,{}),"\n",(0,t.jsx)(r.p,{children:"Process video frames in real-time to apply filters, perform analysis, or integrate with ML models. Built for performance with native optimization."}),"\n",(0,t.jsx)(r.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["\u{1F3A8} ",(0,t.jsx)(r.strong,{children:"Real-time filters"})," - Apply visual effects during playback"]}),"\n",(0,t.jsxs)(r.li,{children:["\u{1F50D} ",(0,t.jsx)(r.strong,{children:"Object detection"})," - Identify objects, faces, or text in video"]}),"\n",(0,t.jsxs)(r.li,{children:["\u{1F4CA} ",(0,t.jsx)(r.strong,{children:"Video analytics"})," - Extract metadata and insights"]}),"\n",(0,t.jsxs)(r.li,{children:["\u{1F3AE} ",(0,t.jsx)(r.strong,{children:"AR integration"})," - Overlay augmented reality content"]}),"\n",(0,t.jsxs)(r.li,{children:["\u{1F512} ",(0,t.jsx)(r.strong,{children:"Watermarking"})," - Add dynamic watermarks to video"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"features",children:"Features"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Native performance"})," - Process frames at full FPS"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"GPU acceleration"})," - Leverage device GPU for heavy processing"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Worklet support"})," - Run JavaScript on the video thread"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"ML integration"})," - Connect with TensorFlow, Core ML, etc."]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Low latency"})," - Minimal delay in frame processing"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-tsx",children:"import Video from 'react-native-video';\nimport { useFrameProcessor } from 'react-native-video-pro';\n\nfunction VideoWithFrameProcessor() {\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet';\n    \n    // Access frame data\n    const width = frame.width;\n    const height = frame.height;\n    const timestamp = frame.timestamp;\n    \n    // Process the frame\n    // Return modified frame or analysis results\n    return frame;\n  }, []);\n\n  return (\n    <Video\n      source={{ uri: 'https://example.com/video.mp4' }}\n      frameProcessor={frameProcessor}\n      style={{ width: '100%', height: 300 }}\n    />\n  );\n}\n"})}),"\n",(0,t.jsx)(r.h2,{id:"applying-filters",children:"Applying Filters"}),"\n",(0,t.jsx)(r.p,{children:"Apply real-time visual filters:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-tsx",children:"import { useFrameProcessor, applyFilter } from 'react-native-video-pro';\n\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  \n  // Apply grayscale filter\n  return applyFilter(frame, 'grayscale');\n  \n  // Or sepia\n  // return applyFilter(frame, 'sepia');\n  \n  // Or custom color matrix\n  // return applyFilter(frame, 'colorMatrix', {\n  //   matrix: [...]\n  // });\n}, []);\n"})}),"\n",(0,t.jsx)(r.h2,{id:"object-detection",children:"Object Detection"}),"\n",(0,t.jsx)(r.p,{children:"Detect objects using ML models:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-tsx",children:"import { useFrameProcessor, detectObjects } from 'react-native-video-pro';\n\nfunction VideoWithDetection() {\n  const [detections, setDetections] = useState([]);\n\n  const frameProcessor = useFrameProcessor((frame) => {\n    'worklet';\n    \n    const results = detectObjects(frame, {\n      model: 'yolov5',\n      confidence: 0.5,\n    });\n    \n    // Send results back to JS thread\n    runOnJS(setDetections)(results);\n    \n    return frame;\n  }, []);\n\n  return (\n    <View>\n      <Video\n        source={{ uri: 'https://example.com/video.mp4' }}\n        frameProcessor={frameProcessor}\n        style={styles.video}\n      />\n      <DetectionOverlay detections={detections} />\n    </View>\n  );\n}\n"})}),"\n",(0,t.jsx)(r.h2,{id:"face-detection",children:"Face Detection"}),"\n",(0,t.jsx)(r.p,{children:"Detect and track faces:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-tsx",children:"import { useFrameProcessor, detectFaces } from 'react-native-video-pro';\n\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  \n  const faces = detectFaces(frame, {\n    performanceMode: 'fast',\n    landmarkMode: 'all',\n    contourMode: 'none',\n  });\n  \n  faces.forEach(face => {\n    console.log('Face bounds:', face.bounds);\n    console.log('Smile probability:', face.smilingProbability);\n  });\n  \n  return frame;\n}, []);\n"})}),"\n",(0,t.jsx)(r.h2,{id:"watermarking",children:"Watermarking"}),"\n",(0,t.jsx)(r.p,{children:"Add dynamic watermarks:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-tsx",children:"import { useFrameProcessor, addWatermark } from 'react-native-video-pro';\n\nconst frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  \n  return addWatermark(frame, {\n    text: '\xa9 MyApp 2024',\n    position: 'bottomRight',\n    opacity: 0.7,\n    fontSize: 14,\n    color: '#ffffff',\n  });\n}, []);\n"})}),"\n",(0,t.jsx)(r.h2,{id:"performance-tips",children:"Performance Tips"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Use worklets"})," - Always include ",(0,t.jsx)(r.code,{children:"'worklet'"})," directive"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Minimize JS bridge calls"})," - Batch updates with ",(0,t.jsx)(r.code,{children:"runOnJS"})]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Optimize processing frequency"})," - Skip frames if needed"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Use GPU when possible"})," - Leverage hardware acceleration"]}),"\n"]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-tsx",children:"const frameProcessor = useFrameProcessor((frame) => {\n  'worklet';\n  \n  // Skip every other frame for performance\n  if (frame.timestamp % 2 === 0) {\n    return frame;\n  }\n  \n  // Heavy processing here\n  return processFrame(frame);\n}, []);\n"})}),"\n",(0,t.jsx)(r.h2,{id:"get-started",children:"Get Started"}),"\n",(0,t.jsx)(r.p,{children:"Ready to process video frames?"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Start a free trial"})," - ",(0,t.jsx)(r.a,{href:"https://sdk.thewidlarzgroup.com/signup?utm_source=rnv&utm_medium=docs&utm_campaign=frame-processor",children:"Sign up here"})]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Contact our team"})," - ",(0,t.jsx)(r.a,{href:"https://www.thewidlarzgroup.com/?utm_source=rnv&utm_medium=docs&utm_campaign=frame-processor#Contact",children:"Get in touch"})]}),"\n"]})]})}function p(e={}){let{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(m,{...e})}):m(e)}},4713:function(e,r,n){n.d(r,{A:()=>i});var s=n(4848);let t={container:"container_BXhl",text:"text_KtV3",proPlayer:"proPlayer_sNNV"},i=()=>(0,s.jsx)("div",{className:t.container,children:(0,s.jsxs)("span",{className:t.text,children:["This feature is part of the ",(0,s.jsx)("strong",{className:t.proPlayer,children:"Pro Player"})," plan. Pricing information can be found ",(0,s.jsx)("span",{className:t.here,children:"here"}),"."]})})},6151:function(e,r,n){n.d(r,{R:()=>a,x:()=>o});var s=n(6540);let t={},i=s.createContext(t);function a(e){let r=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function o(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(i.Provider,{value:r},e.children)}}}]);